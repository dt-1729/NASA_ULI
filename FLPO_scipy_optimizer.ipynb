{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dhananjay Tiwari,\n",
    "Ph.D. Mechanical Engineering,\n",
    "Mechanical Engineering Laboratory, 1204\n",
    "University of Illinois at Urbana Champaign"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has the code for implementation of FLPO optimization problem using using scipy optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include libraries and dependencies\n",
    "import numpy as np # eh! computational python programming and not include this? Can't happen!\n",
    "import matplotlib.pyplot as plt # module to make plots\n",
    "from scipy import optimize # optimization module in scipy\n",
    "from scipy.optimize import minimize # minimize function using various algorithms\n",
    "from scipy.optimize import LinearConstraint # to define linear constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create FLPO class and define its associated functions\n",
    "class FLPO():\n",
    "\n",
    "    # define data members of the class\n",
    "    N : int # number of vehicles\n",
    "    M : int # number of nodes\n",
    "    K : int # number of stages\n",
    "    uav_id : list # vehicle indices\n",
    "    node_id : list # facility indices\n",
    "    stop_id : list # destination id\n",
    "    node_param : dict # node parameters\n",
    "    num_param : dict # number of parameters\n",
    "\n",
    "    stages : list # FLPO stages, K elements\n",
    "                  #   Nx1  (M+1)x1  (M+1)x1   (M+1)x1    (M+1)x1       1x1\n",
    "                  #   stg0   stg1    stg2     stg3 . . . . stgK-2     stgK-1\n",
    "                  #    0      0        0        0  . . . .  0               \n",
    "                  #    1      1        1        1  . . . .  1\n",
    "                  #    2      2        2        2  . . . .  2          dest\n",
    "                  #    .      .        .        .  . . . .  .\n",
    "                  #    .      .        .        .  . . . .  .\n",
    "                  #    .      M-1      M-1      M-1  . . .  M-1\n",
    "                  #    .      dest    dest     dest  . . .  dest\n",
    "                  #    N-1    \n",
    "    \n",
    "    asn_pb : list # list of list of arrays\n",
    "                  #  --------------                                                                           --------------\n",
    "                  # |          stagewise probability associations for a vehicle i = 0,1, . . , N-1                          |\n",
    "                  # |    -----                                                                     -----                    |\n",
    "                  # |   |                                                                               |                   |\n",
    "                  # |   |   stg0 ----> stg1 ----------> stg2 -----> . . . . ----> stg(K-1) -----> stgK  |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |  . . . . .        |\n",
    "                  # |   |  1x|stg1|  |stg1|x|stg2|    |stg2|x|stg3|   . . . .    |stg(K-1)|x|stgK|      |                   |\n",
    "                  # |   |  matrix     matrix            matrix  . . . . . . .      matrix               |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |                   |\n",
    "                  # |   |     .          .                .     . . . . . . .         .                 |                   |\n",
    "                  # |    -----                                                                     -----                    |\n",
    "                  #  -------------                                                                            --------------\n",
    "\n",
    "    num_asn_pb : int # number of probability associations\n",
    "\n",
    "    def __init__(self, N, M):\n",
    "        # this function intializes the FLPO structure with assigned values\n",
    "        \n",
    "        # UAVs, nodes and stopping state indices\n",
    "        self.N = N # initialize the number of vehicles\n",
    "        self.M = M # initialize the number of nodes\n",
    "        self.K = self.M + 2 # 1 initial stage + #intermediate stages equal to the number of facilities + 1 final stage\n",
    "        self.uav_id = list(range(N)) # 0 1 2 . . . N-1\n",
    "        self.node_id = list(range(N, N+M)) # N N+1 . . . N+M-1\n",
    "        self.stop_id = list(range(N+M, N+M+1)) # N+M\n",
    "        # initialize the initial and terminal nodes of all the UAVs as zeros\n",
    "        self.uav_init = list(range(N)) # this value to be given by the user\n",
    "        self.uav_stop = list(range(N)) # this value to be given by the user\n",
    "        # initialize parameters associated to all the facilities\n",
    "        self.node_param = dict()\n",
    "        # self.fac_param['locations'] = np.zeros([M, 2])\n",
    "        self.node_param['schedules'] = np.zeros([M, N]) # all M nodes have N components for each vehicle\n",
    "        self.num_param['schedules'] = M*N # the total numbe of parameters is number of nodes times the number of vehicles\n",
    "\n",
    "        # define the structure of the stages and the elements in them\n",
    "        self.stages = [0 for element in range(self.K)] # initialize list stages. Each 0 to be replaced with a column vector\n",
    "        for stg in range(self.K):\n",
    "            if stg == 0:\n",
    "                # initial stage consisting of nodes\n",
    "                self.stages[stg] = self.uav_id # Nx1 array\n",
    "            elif stg == self.K-1:\n",
    "                # final stage consists of only stopping state\n",
    "                self.stages[stg] = self.stop_id # 1x1 array\n",
    "            else:\n",
    "                # other stages consist of facilities and destination\n",
    "                self.stages[stg] = self.node_id + self.stop_id # (M+1) x 1 array\n",
    "        \n",
    "        # initialize association probabilities\n",
    "        self.asn_pb = [[0 for element1 in range(self.K-1)] for element2 in range(N)]\n",
    "        for n in range(N): # iteration over each node in the initial stage\n",
    "            for stg in range(self.K-1): # iteration goes until the penultimate stage\n",
    "                next_stage = self.stages[stg+1] # get the next stage nodes\n",
    "                # initialize probabilities as ones (normalized in the next step)\n",
    "                if stg == 0:\n",
    "                    # self.asn_pb[n][stg] = np.ones([1, len(next_stage)]) # uniform distribution\n",
    "                    self.asn_pb[n][stg] = np.random.rand(1, len(next_stage)) # normal distribution\n",
    "                    self.asn_pb[n][stg] = self.asn_pb[n][stg]/self.asn_pb[n][stg].sum(axis = 1)[:, None] # normalize\n",
    "                else:\n",
    "                    # self.asn_pb[n][stg] = np.ones([len(self.stages[stg]), len(self.stages[stg+1])]) # uniform distribution\n",
    "                    self.asn_pb[n][stg] = np.random.rand(len(self.stages[stg]), len(self.stages[stg+1])) # normal distribution\n",
    "                    self.asn_pb[n][stg] = self.asn_pb[n][stg]/self.asn_pb[n][stg].sum(axis = 1)[:, None] # normalize\n",
    "\n",
    "        print('\\n -- FLPO Initialized -- ')\n",
    "\n",
    "    # assign an initial node to a UAV\n",
    "    def set_init_node(self, uav, init_node):\n",
    "        id_uav = self.uav_id.index(uav) # get the UAV index\n",
    "        self.uav_init[id_uav] = init_node # assign the initial node to the corresponding index\n",
    "    \n",
    "    # access the initial node of a UAV\n",
    "    def get_init_node(self, uav):\n",
    "        id_uav = self.uav_id.index(uav) # get the UAV index\n",
    "        return self.uav_init[id_uav] # return the corresponding UAV initial node\n",
    "    \n",
    "    # assign a terminal node to a UAV\n",
    "    def set_stop_node(self, uav, stop_node):\n",
    "        id_uav = self.uav_id.index(uav) # get the UAV index\n",
    "        self.uav_stop[id_uav] = stop_node # assign the terminal node to the corresponding index\n",
    "\n",
    "    # access the terminal node of a UAV\n",
    "    def get_stop_node(self, uav):\n",
    "        id_uav = self.uav_id.index(uav) # get the UAV index\n",
    "        return self.uav_stop[id_uav] # return the corresponding UAV terminal node\n",
    "\n",
    "    # define stage transportation cost for each node        \n",
    "    def cost_stage_transit(self, n, stg, i, j):\n",
    "        # this function gives the value of stage transition cost for node n\n",
    "        # from node i in stage stg to node j in stage stg+1\n",
    "        # for now the cost is defined based on the facility schedules\n",
    "        # print(' -- Data type of node parameters -- ' , type(self.node_param))\n",
    "        t = self.node_param['schedules'] # a 2D matrix with each row representing a facility, and every column representing a node\n",
    "        # get the indices of i and j and vehicle n\n",
    "        id_i = self.stages[stg].index(i)\n",
    "        id_j = self.stages[stg+1].index(j)\n",
    "        id_n = self.uav_id.index(n)\n",
    "\n",
    "        # define the constant for lower and upper time bound penalties respectively\n",
    "        nu = 1\n",
    "        eta = 1\n",
    "        \n",
    "        cost = 0\n",
    "        if i in self.node_id and j in self.node_id:\n",
    "            # time taken to move from node i to node j by vehicle n in intermediate nodes\n",
    "            # the cost penalizes vehicles if they take a minimum of 30 second and a maximum of 80 second\n",
    "            # to traverse between the nodes\n",
    "            cost = t[id_j, id_n] - t[id_i, id_n] + \\\n",
    "                 np.exp(nu * (1 - (t[id_j, id_n] - t[id_i, id_n]))) + \\\n",
    "                    np.exp(eta * ((t[id_j, id_n] - t[id_i, id_n]) - 3))\n",
    "            \n",
    "        elif i in self.node_id and j in self.stop_id:\n",
    "            # if transition is from a node to stopping state\n",
    "            if i == self.get_stop_node(n):\n",
    "                # if the current node is the destination of vehicle n then zero cost\n",
    "                cost = 0\n",
    "            else:\n",
    "                # else high penalty\n",
    "                cost = 100\n",
    "        \n",
    "        elif i in self.stop_id and j in self.node_id:\n",
    "            # if transition is from a stopping state to a node\n",
    "            cost = 100 # the penalty is high\n",
    "        \n",
    "        elif i in self.stop_id and j in self.stop_id:\n",
    "            # zero cost for stage-transition from stop to stop\n",
    "            cost = 0\n",
    "\n",
    "        return cost\n",
    "    \n",
    "\n",
    "    # define the distortion function of a node \n",
    "    def distortion(self, n): \n",
    "        # this function computes the distortion function of a node n using probability associations and parameters of facilities for the corresponding vehicle\n",
    "        if n not in self.uav_id: # check if the vehicle argument is valid or not\n",
    "            print('invalid node id')\n",
    "        else:\n",
    "            # initialize the distortion data structure (same as stages data structure)\n",
    "            D = [np.zeros(1)]\n",
    "            D = D + [np.zeros(len(self.stages[stg])) for stg in range(1,self.K)]\n",
    "            # print('\\n-- Distortion Matrix --\\n')\n",
    "            # print(D)\n",
    "            # for row in D:\n",
    "            #     print(row)\n",
    "\n",
    "            # iterate over stages : final stage --> initial stage\n",
    "            stg_ids = list(range(self.K))\n",
    "            stg_ids_rev = stg_ids[::-1]\n",
    "            for stg in stg_ids_rev:\n",
    "                # print('stage -- ' , stg)\n",
    "                # iterate over each element of the chosen stage\n",
    "                if stg > 0:\n",
    "                    for i in self.stages[stg]:\n",
    "                        id_i = self.stages[stg].index(i)\n",
    "                        # print('  i -- ' , i, id_i)\n",
    "                        D[stg][id_i] = 0\n",
    "                        if stg == self.K-1:\n",
    "                            D[stg][id_i] = 0\n",
    "                        else:\n",
    "                            for j in self.stages[stg+1]:\n",
    "                                id_j = self.stages[stg+1].index(j)\n",
    "                                # print('    j -- ' , j , id_j, D[stg][id_i])\n",
    "                                D[stg][id_i] = D[stg][id_i] + self.asn_pb[n][stg][id_i, id_j] * (D[stg+1][id_j] + self.cost_stage_transit(n, stg, i, j))\n",
    "                elif stg == 0:\n",
    "                    i = n\n",
    "                    id_i = 0\n",
    "                    # print('  i -- ' , i , id_i)\n",
    "                    for j in self.stages[stg+1]:\n",
    "                        id_j = self.stages[stg+1].index(j)\n",
    "                        # print( '    j -- ' , j, id_j, self.cost_stage_transit(n, stg, i, j))\n",
    "                        D[stg][id_i] = D[stg][id_i] + self.asn_pb[n][stg][id_i, id_j] * (D[stg+1][id_j] + self.cost_stage_transit(n, stg, i, j))\n",
    "        return D[0][0]\n",
    "    \n",
    "\n",
    "    def entropy(self, n): # depends on probability associations\n",
    "        # ToDo\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def free_energy():\n",
    "        # ToDo\n",
    "        return 0\n",
    "\n",
    "\n",
    "    def flat_asn_pb(self, asn_pb):\n",
    "        # this function unwraps the association probabilities into a column vector\n",
    "\n",
    "        vec = []\n",
    "        # unwrap for a vehicle, and then put them all together\n",
    "        for uav_pb in asn_pb:\n",
    "            for stg_pb in uav_pb:\n",
    "                vec = vec + list(stg_pb.flatten())\n",
    "\n",
    "        return vec\n",
    "\n",
    "\n",
    "    def wrap_flat_asn_pb(self, vec_asn_pb):\n",
    "        # this function wraps the association probabilities into their original defined structure inside __init__() function\n",
    "        # vec_asn_pb (list) should contain probability association corresponding to all the vehicles otherwise the function prints error\n",
    "\n",
    "        # initialize the required structure of association probability we need\n",
    "        asn_pb = [[0 for element1 in range(self.K-1)] for element2 in range(self.N)]\n",
    "\n",
    "        # get the dimension of probability association for a single vehicle\n",
    "        dim_uav = 0\n",
    "        # iterate over the stages to compute the above required dimension\n",
    "        for stg in range(self.K-1):\n",
    "            if stg == 0:\n",
    "                dim_uav = dim_uav + len(self.stages[stg+1])\n",
    "            else:\n",
    "                dim_uav = dim_uav + len(self.stages[stg])*len(self.stages[stg+1])\n",
    "        \n",
    "        # dim_uav times the number of vehicles should be dim of vec_asn_pb\n",
    "        if dim_uav * len(self.uav_id) != int(len(vec_asn_pb)):\n",
    "            print('invalid dimension of association probability vector')\n",
    "        else:\n",
    "            for uav in self.uav_id:\n",
    "                # get the index of uav\n",
    "                n = self.uav_id.index(uav)\n",
    "                # slice the probability vector for the corresponding vehicle\n",
    "                sliced_vec = vec_asn_pb[n*dim_uav : (n+1)*dim_uav]\n",
    "                k = 0\n",
    "                for stg in range(self.K-1):\n",
    "                    if stg == 0:\n",
    "                        asn_pb[n][stg] = np.reshape( sliced_vec[k : k + 1*len(self.stages[stg+1])] , [1, len(self.stages[stg+1])] )\n",
    "                        k = k + 1*len(self.stages[stg+1])\n",
    "                    else:\n",
    "                        asn_pb[n][stg] = np.reshape( sliced_vec[k : k + len(self.stages[stg])*len(self.stages[stg+1])] , [len(self.stages[stg]), len(self.stages[stg+1])] )\n",
    "                        k = k + len(self.stages[stg])*len(self.stages[stg+1])\n",
    "        \n",
    "        return asn_pb\n",
    "\n",
    "\n",
    "    def flat_schedules(self, schedules):\n",
    "        # this converts the original data structure of schedules (see __init__() function) into a 1D array\n",
    "        return list(schedules.flatten())\n",
    "\n",
    "\n",
    "    def wrap_flat_schedules(self, vec_schedules):\n",
    "        # this converts the 1D array of schedules into its original defined structure (see __init__() function)\n",
    "\n",
    "        # first check if the dimension is correct\n",
    "        dim = len(vec_schedules)\n",
    "        # print('length of flattened schedules = ' , len(vec_schedules))\n",
    "        # print('number of nodes = ' , len(self.node_id))\n",
    "        # print('number of UAVs = ' , len(self.uav_id))\n",
    "        if dim != len(self.node_id) * len(self.uav_id):\n",
    "            print('invalid dimension of the parameters for time-schedule')\n",
    "\n",
    "        schedules = np.reshape(vec_schedules, [len(self.node_id), len(self.uav_id)])\n",
    "\n",
    "        return schedules\n",
    "    \n",
    "\n",
    "    def get_num_asn_pb(self):\n",
    "        # this function outputs the number of probability association variables in the problem\n",
    "\n",
    "        # get the number of probability association variables\n",
    "        dim_pb = 0\n",
    "        # iterate over the stages to compute the above required dimension\n",
    "        for n in range(self.N):\n",
    "            for stg in range(self.K-1):\n",
    "                if stg == 0: # in the zeroth stage only 1 vehicle is considered and multiplied with the dimension of the stage 1\n",
    "                    dim_pb = dim_pb + 1 * len(self.stages[stg+1])\n",
    "                else: # otherwise the original dimensions of the current stage is multiplied with that the next one\n",
    "                    dim_pb = dim_pb + len(self.stages[stg]) * len(self.stages[stg+1])\n",
    "\n",
    "        return dim_pb\n",
    "\n",
    "\n",
    "    def cons_asn_pb(self, vec_asn_pb):\n",
    "        # this function constraints the distributions that the sum of probabilities at every node is 1 for every vehicle\n",
    "        # input : consists of all the probability associations in the vector form\n",
    "        # output : returns a fat matrix resulting from the linear combinations from all the equations, \n",
    "        #          lower bounds and upper bounds\n",
    "\n",
    "        # get the dimension of probability association for a single vehicle\n",
    "        dim_uav = 0\n",
    "        # iterate over the stages to compute the above required dimension\n",
    "        for stg in range(self.K-1):\n",
    "            if stg == 0: # in the zeroth stage only 1 vehicle is considered and multiplied with the dimension of stage 1\n",
    "                dim_uav = dim_uav + 1 * len(self.stages[stg+1])\n",
    "            else: # otherwise the original dimensions of the current stage is multiplied with that the next one\n",
    "                dim_uav = dim_uav + len(self.stages[stg]) * len(self.stages[stg+1])\n",
    "        \n",
    "        # print('dim_uav = ' , dim_uav)\n",
    "        # print('number of UAVs = ' , len(self.uav_id))\n",
    "        # print('length of flattened associations = ' , len(vec_asn_pb))\n",
    "        # dim_uav times the number of vehicles should be dim of vec_asn_pb\n",
    "        if dim_uav * len(self.uav_id) != len(vec_asn_pb):\n",
    "            print('invalid dimension of association probability vector')\n",
    "\n",
    "        # the number of equality constraints is equal to the sum of cardinality of every stage (except the first and the final stage)\n",
    "        num_eq_cons = 0\n",
    "        # iterate over the vehicles\n",
    "        for n in range(self.N):\n",
    "            # iterate till the penultimate stage\n",
    "            for stg in range(self.K-1):\n",
    "                if stg == 0: # in the initial stage, only vehicle n is counted\n",
    "                    num_eq_cons = num_eq_cons + 1\n",
    "                else: # otherwise count all the nodes in a stage\n",
    "                    num_eq_cons = num_eq_cons + len(self.stages[stg])\n",
    "\n",
    "        # initialize the linear constraint matrix\n",
    "        fat_mat = [[0 for i in range(len(vec_asn_pb))] for j in range(num_eq_cons)]\n",
    "        # initialize counters\n",
    "        row_count = 0 # to trace rows of fat_mat\n",
    "        col_count = 0 # to trace cols of fat_mat\n",
    "        # iterate over vehicles\n",
    "        for n in range(self.N):\n",
    "            # corresponding to the first transition of a vehicle\n",
    "            # iterate over stages from 1 to K-1\n",
    "            for stg in range(self.K-1):\n",
    "                if stg == 0:\n",
    "                    # iteration over stage 1 for columns of fat_mat in the first row\n",
    "                    for j in range(len(self.stages[stg+1])):\n",
    "                        fat_mat[row_count][col_count] = 1\n",
    "                        col_count = col_count + 1 # update column count for the next column\n",
    "                    row_count = row_count + 1 # update row count for the next row\n",
    "                else:\n",
    "                    # iterate over the rows that correspond to the current stage\n",
    "                    for i in range(len(self.stages[stg])):\n",
    "                        # iterate over the that cols correspond to the next stage\n",
    "                        for j in range(len(self.stages[stg+1])):\n",
    "                            fat_mat[row_count][col_count] = 1\n",
    "                            col_count = col_count + 1 # update column count for the next column\n",
    "                        row_count = row_count + 1 # update row count for the next row\n",
    "\n",
    "        # define the lower bound for linear inequality/equality constraints\n",
    "        lb = list(np.ones(num_eq_cons)) # all probability distributions sum to 1\n",
    "        # define the upper bound for linear inquality/equality constraints (equal to lb in case of equality)\n",
    "        ub = list(np.ones(num_eq_cons)) # all probability distributions sum to 1\n",
    "\n",
    "        # define the linear constraint in the form needed for scicpy.optimize.minimize\n",
    "        # lin_con = LinearConstraint(fat_mat, lb, ub) \n",
    "\n",
    "        # print('dimension of fat_matrix = (' , len(fat_mat), len(fat_mat[0]), ')' )\n",
    "        # print('dimension of lower bound vector = ' , len(lb))\n",
    "        # print('dimension of upper bound vector = ' , len(ub))\n",
    "\n",
    "        return fat_mat, lb, ub\n",
    "    \n",
    "\n",
    "    def cons_schedules(self, x):\n",
    "        # this function gives the matrices corresponding constraints on the time-schedule parameters\n",
    "        # input : the decision variable consisiting of flattened probability associations \n",
    "        #         and flattened time-schedule parameters\n",
    "        # output : matrices corresponding to linear combination of time schedules, upper bound and lower bound vectors\n",
    "\n",
    "        # fetch the total number of probability associations\n",
    "        dim_pb = self.get_num_asn_pb()\n",
    "\n",
    "        # fetch the flattened time-schedules\n",
    "        t = x[dim_pb:]\n",
    "\n",
    "        # check if the dimension of t is number of nodes times the number of vehicles\n",
    "        if len(t) != self.N * self.M:\n",
    "            print('invalid dimension of flattened time-schedules')\n",
    "\n",
    "        # create matrix to compute the linear combinations of all the elements \n",
    "        fat_mat = list(np.eye(len(t)))\n",
    "        for r in len(fat_mat):\n",
    "            fat_mat[r] = list(fat_mat[r])\n",
    "        # create lower and upper bound matrices\n",
    "        lb = [0 for el in range(len(t))]\n",
    "        ub = [np.inf for el in range(len(t))]\n",
    "\n",
    "        # get init nodes\n",
    "        for n in self.uav_id:\n",
    "            id_n = self.node_id.index(n) # get the vehicle index\n",
    "            init_node = self.get_init_node(n) # get the start node of the vehicle\n",
    "            id_init = self.node_id.index(init_node) # get the index of the start node\n",
    "            ub[id_init*self.N + id_n] = 0.0 # set the corresponding upper bound value equal to the start time\n",
    "            lb[id_init*self.N + id_n] = 0.0 # set the corresponding lower bound value equal to the start time\n",
    "\n",
    "        return fat_mat, lb, ub\n",
    "\n",
    "\n",
    "    def cons(self, x):\n",
    "        # this function defined all linear and nonlinear constraints for the system as per the requirements\n",
    "        # input: the decision variable consisting of flattened probability associations stacked with \n",
    "        #        flattened schedule parameters  \n",
    "        # output: scipy.optimize_constraints methods for linear and nonlinear constraints\n",
    "\n",
    "        # get the number of probability association variables\n",
    "        dim_pb = self.get_num_asn_pb()\n",
    "\n",
    "        pb_mat, pb_lb, pb_ub = self.cons_asn_pb(x[0:dim_pb]) # get the probability linear constraint matrices\n",
    "        param_mat, param_lb, param_ub = self.cons_schedules(x[dim_pb:]) # get the schedule linear constraint matrices\n",
    "\n",
    "        for row in pb_mat:\n",
    "            row = row + list(np.zeros(len(x[dim_pb:]))) # concatenation of lists\n",
    "\n",
    "        for row in param_mat:\n",
    "            row = list(np.zeros(len(x[0:dim_pb]))) + row # concatenation of lists\n",
    "\n",
    "        mat = pb_mat + param_mat # concatenation of lists\n",
    "        lb = pb_lb + param_lb # concatenation of lists\n",
    "        ub = pb_ub + param_ub # concatenation of lists\n",
    "\n",
    "        lincon = LinearConstraint(mat, lb, ub)\n",
    "\n",
    "        return lincon #, non_lincon\n",
    "    \n",
    "\n",
    "    def objective(self, x):\n",
    "        # this function computes the objective of the FLPO problem from distortion of each vehicle and entropy\n",
    "        # of probability associations for each vehicle\n",
    "        # input : x = [ flat_asn_pb , time_schedules ] is a vector consisting of all the probability associations and node time schedule parameters\n",
    "\n",
    "        # get the number of probability association variables\n",
    "        dim_pb = 0\n",
    "        # iterate over the stages to compute the above required dimension\n",
    "        for n in range(self.N):\n",
    "            for stg in range(self.K-1):\n",
    "                if stg == 0: # in the zeroth stage only 1 vehicle is considered and multiplied with the dimension of the stage 1\n",
    "                    dim_pb = dim_pb + 1 * len(self.stages[stg+1])\n",
    "                else: # otherwise the original dimensions of the current stage is multiplied with that the next one\n",
    "                    dim_pb = dim_pb + len(self.stages[stg]) * len(self.stages[stg+1])\n",
    "        # print('<< Inside objective() function >> \\n << print the number of association probabilities >> ' , dim_pb)\n",
    "        asn_pb = self.wrap_flat_asn_pb(x[0:dim_pb]) # probability association component of x\n",
    "        params = self.wrap_flat_schedules(x[dim_pb:]) # time-schedules component of x\n",
    "        \n",
    "        # assign the association probabilities and node parameters \n",
    "        self.asn_pb = asn_pb\n",
    "        self.node_param['schedules'] = params\n",
    "\n",
    "        # initialize the total cost\n",
    "        cost = 0\n",
    "\n",
    "        # initialize the weights given to each vehicle\n",
    "        uav_weights = np.ones(len(self.uav_id))/len(self.uav_id) # uniform distribution for now\n",
    "\n",
    "\n",
    "        # compute distortion cost by performing weighted sum over each vehicle\n",
    "        distortion_cost = 0\n",
    "        for n in self.uav_id:\n",
    "            id_n = self.uav_id.index(n) # get index\n",
    "            distortion_cost = distortion_cost + uav_weights[id_n] * self.distortion(n) # update the weighed sum\n",
    "\n",
    "        # ToDo : compute entropy cost by performing weighted sum over each vehicle\n",
    "        \n",
    "        # total cost\n",
    "        cost = distortion_cost # + entropy_cost\n",
    "        # print(' distortion cost = ' , cost)\n",
    "\n",
    "        return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the distortion of FLPO with respect to probability associations and node schedule parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -- FLPO Initialized -- \n",
      "\n",
      " -- FLPO Stages -- \n",
      " [[0], [1, 2, 3], [1, 2, 3], [3]]\n",
      "\n",
      " -- FLPO Associations -- \n",
      " [[array([[0.25810494, 0.59103307, 0.15086199]]), array([[0.19093261, 0.30529575, 0.50377164],\n",
      "       [0.15793314, 0.40959966, 0.4324672 ],\n",
      "       [0.34175111, 0.19796634, 0.46028255]]), array([[1.],\n",
      "       [1.],\n",
      "       [1.]])]]\n",
      "dimension of fat_matrix = ( 7 15 )\n",
      "dimension of lower bound vector =  7\n",
      "dimension of upper bound vector =  7\n",
      "<scipy.optimize._constraints.LinearConstraint object at 0x127be30d0>\n",
      "\n",
      " -- The total dimension of decision variables =  17 -- \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (7,15) and (17,) not aligned: 15 (dim 1) != 17 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(probability_cons)\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m -- The total dimension of decision variables = \u001b[39m\u001b[39m'\u001b[39m , \u001b[39mlen\u001b[39m(x0) , \u001b[39m'\u001b[39m\u001b[39m-- \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m res \u001b[39m=\u001b[39m minimize(flpo\u001b[39m.\u001b[39;49mobjective, x0, constraints \u001b[39m=\u001b[39;49m probability_cons)\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_minimize.py:629\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_custom\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    622\u001b[0m     \u001b[39m# custom method called before bounds and constraints are 'standardised'\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     \u001b[39m# custom method should be able to accept whatever bounds/constraints\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[39m# are provided to it.\u001b[39;00m\n\u001b[1;32m    625\u001b[0m     \u001b[39mreturn\u001b[39;00m method(fun, x0, args\u001b[39m=\u001b[39margs, jac\u001b[39m=\u001b[39mjac, hess\u001b[39m=\u001b[39mhess, hessp\u001b[39m=\u001b[39mhessp,\n\u001b[1;32m    626\u001b[0m                   bounds\u001b[39m=\u001b[39mbounds, constraints\u001b[39m=\u001b[39mconstraints,\n\u001b[1;32m    627\u001b[0m                   callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m--> 629\u001b[0m constraints \u001b[39m=\u001b[39m standardize_constraints(constraints, x0, meth)\n\u001b[1;32m    631\u001b[0m remove_vars \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m bounds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_minimize.py:970\u001b[0m, in \u001b[0;36mstandardize_constraints\u001b[0;34m(constraints, x0, meth)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[39mfor\u001b[39;00m i, con \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mlist\u001b[39m(constraints)):\n\u001b[1;32m    969\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(con, new_constraint_types):\n\u001b[0;32m--> 970\u001b[0m         old_constraints \u001b[39m=\u001b[39m new_constraint_to_old(con, x0)\n\u001b[1;32m    971\u001b[0m         constraints[i] \u001b[39m=\u001b[39m old_constraints[\u001b[39m0\u001b[39m]\n\u001b[1;32m    972\u001b[0m         constraints\u001b[39m.\u001b[39mextend(old_constraints[\u001b[39m1\u001b[39m:])  \u001b[39m# appends 1 if present\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_constraints.py:469\u001b[0m, in \u001b[0;36mnew_constraint_to_old\u001b[0;34m(con, x0)\u001b[0m\n\u001b[1;32m    465\u001b[0m     jac \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: A\n\u001b[1;32m    467\u001b[0m \u001b[39m# FIXME: when bugs in VectorFunction/LinearVectorFunction are worked out,\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# use pcon.fun.fun and pcon.fun.jac. Until then, get fun/jac above.\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m pcon \u001b[39m=\u001b[39m PreparedConstraint(con, x0)\n\u001b[1;32m    470\u001b[0m lb, ub \u001b[39m=\u001b[39m pcon\u001b[39m.\u001b[39mbounds\n\u001b[1;32m    472\u001b[0m i_eq \u001b[39m=\u001b[39m lb \u001b[39m==\u001b[39m ub\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_constraints.py:334\u001b[0m, in \u001b[0;36mPreparedConstraint.__init__\u001b[0;34m(self, constraint, x0, sparse_jacobian, finite_diff_bounds)\u001b[0m\n\u001b[1;32m    328\u001b[0m     fun \u001b[39m=\u001b[39m VectorFunction(constraint\u001b[39m.\u001b[39mfun, x0,\n\u001b[1;32m    329\u001b[0m                          constraint\u001b[39m.\u001b[39mjac, constraint\u001b[39m.\u001b[39mhess,\n\u001b[1;32m    330\u001b[0m                          constraint\u001b[39m.\u001b[39mfinite_diff_rel_step,\n\u001b[1;32m    331\u001b[0m                          constraint\u001b[39m.\u001b[39mfinite_diff_jac_sparsity,\n\u001b[1;32m    332\u001b[0m                          finite_diff_bounds, sparse_jacobian)\n\u001b[1;32m    333\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(constraint, LinearConstraint):\n\u001b[0;32m--> 334\u001b[0m     fun \u001b[39m=\u001b[39m LinearVectorFunction(constraint\u001b[39m.\u001b[39;49mA, x0, sparse_jacobian)\n\u001b[1;32m    335\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(constraint, Bounds):\n\u001b[1;32m    336\u001b[0m     fun \u001b[39m=\u001b[39m IdentityVectorFunction(x0, sparse_jacobian)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:573\u001b[0m, in \u001b[0;36mLinearVectorFunction.__init__\u001b[0;34m(self, A, x0, sparse_jacobian)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mJ\u001b[39m.\u001b[39mshape\n\u001b[1;32m    572\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(x0)\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m--> 573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mJ\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm, dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (7,15) and (17,) not aligned: 15 (dim 1) != 17 (dim 0)"
     ]
    }
   ],
   "source": [
    "# initialize variables\n",
    "N = 1 # number of vehicles\n",
    "M = 2 # number of nodes\n",
    "\n",
    "# define functions\n",
    "def printMatrix(mat , mat_name):\n",
    "    print(mat_name)\n",
    "    for row in mat:\n",
    "        print(row , '\\n')\n",
    "    return 0\n",
    "\n",
    "# create an instance of FLPO class\n",
    "flpo = FLPO(N, M)\n",
    "print('\\n -- FLPO Stages -- \\n' , flpo.stages)\n",
    "print('\\n -- FLPO Associations -- \\n' , flpo.asn_pb)\n",
    "\n",
    "# set the initial and stop points, and initial time for all the UAVs\n",
    "init_nodes = [1]\n",
    "stop_nodes = [2]\n",
    "init_time = [0.0]\n",
    "for i in range(N):\n",
    "    flpo.set_init_node(flpo.uav_id[i], init_nodes[i])\n",
    "    flpo.set_stop_node(flpo.uav_id[i], stop_nodes[i])\n",
    "    flpo.node_param['schedules'][init_nodes[i], i] = init_time[i]\n",
    "\n",
    "# get initial probability associations and time schedule parameters\n",
    "vec_asn_pb = flpo.flat_asn_pb(flpo.asn_pb)\n",
    "vec_schedules = flpo.flat_schedules(flpo.node_param['schedules'])\n",
    "\n",
    "x0 = vec_asn_pb + vec_schedules\n",
    "# print(x0)\n",
    "# print(np.array(vec_asn_pb).shape)\n",
    "probability_cons = flpo.cons_asn_pb(vec_asn_pb)\n",
    "print(probability_cons)\n",
    "print('\\n -- The total dimension of decision variables = ' , len(x0) , '-- ')\n",
    "res = minimize(flpo.objective, x0, constraints = probability_cons)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -1091676179.3121512\n",
      " hess_inv: array([[ 5.93751526e+02,  2.87587419e+01,  7.91324513e+02,\n",
      "         1.63783648e+01, -1.83684045e-01, -6.58985667e+00,\n",
      "         3.47425614e+02,  1.05725548e+01,  0.00000000e+00,\n",
      "        -5.06265429e+02, -2.86909700e+02,  0.00000000e+00,\n",
      "         1.67945991e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -1.69810738e-01,  1.69815099e-01],\n",
      "       [ 2.87587419e+01,  2.37859257e+00,  3.83924635e+01,\n",
      "         7.60671576e-01, -9.92965903e-03, -3.56498277e-01,\n",
      "         1.68621423e+01,  5.13299118e-01,  0.00000000e+00,\n",
      "        -2.46809545e+01, -1.39846145e+01,  0.00000000e+00,\n",
      "         8.10727913e-01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -8.18898138e-03,  8.18919766e-03],\n",
      "       [ 7.91324513e+02,  3.83924635e+01,  1.05741971e+03,\n",
      "         2.18640758e+01, -2.45254311e-01, -8.79876935e+00,\n",
      "         4.63814129e+02,  1.41143948e+01,  0.00000000e+00,\n",
      "        -6.75869408e+02, -3.83027322e+02,  0.00000000e+00,\n",
      "         2.24323879e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -2.26694162e-01,  2.26699986e-01],\n",
      "       [ 1.63783648e+01,  7.60671576e-01,  2.18640758e+01,\n",
      "         1.38349812e+00, -7.14538825e-03, -2.56881008e-01,\n",
      "         9.61188239e+00,  2.92836095e-01,  0.00000000e+00,\n",
      "        -1.42292145e+01, -8.05883252e+00,  0.00000000e+00,\n",
      "         4.57868435e-01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -4.59046694e-03,  4.59059737e-03],\n",
      "       [-1.83684045e-01, -9.92965903e-03, -2.45254311e-01,\n",
      "        -7.14538825e-03,  9.99994779e-01, -2.03463369e-04,\n",
      "        -1.07296983e-01, -3.25509558e-03,  0.00000000e+00,\n",
      "         1.49665515e-01,  8.49694038e-02,  0.00000000e+00,\n",
      "        -5.08941727e-03,  0.00000000e+00,  0.00000000e+00,\n",
      "         5.57168819e-05, -5.57178796e-05],\n",
      "       [-6.58985667e+00, -3.56498277e-01, -8.79876935e+00,\n",
      "        -2.56881008e-01, -2.03463369e-04,  9.92116772e-01,\n",
      "        -3.84929609e+00, -1.16774443e-01,  0.00000000e+00,\n",
      "         5.36753699e+00,  3.04734176e+00,  0.00000000e+00,\n",
      "        -1.82045803e-01,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.99978334e-03, -1.99981894e-03],\n",
      "       [ 3.47425614e+02,  1.68621423e+01,  4.63814129e+02,\n",
      "         9.61188239e+00, -1.07296983e-01, -3.84929609e+00,\n",
      "         2.04632186e+02,  6.19669889e+00,  0.00000000e+00,\n",
      "        -2.96691741e+02, -1.68141414e+02,  0.00000000e+00,\n",
      "         9.84241314e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        -9.95483214e-02,  9.95508754e-02],\n",
      "       [ 1.05725548e+01,  5.13299118e-01,  1.41143948e+01,\n",
      "         2.92836095e-01, -3.25509558e-03, -1.16774443e-01,\n",
      "         6.19669889e+00,  1.18856913e+00,  0.00000000e+00,\n",
      "        -9.02749550e+00, -5.11609508e+00,  0.00000000e+00,\n",
      "         2.99505881e-01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -3.02986855e-03,  3.02994621e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [-5.06265429e+02, -2.46809545e+01, -6.75869408e+02,\n",
      "        -1.42292145e+01,  1.49665515e-01,  5.36753699e+00,\n",
      "        -2.96691741e+02, -9.02749550e+00,  0.00000000e+00,\n",
      "         4.32559672e+02,  2.44590273e+02,  0.00000000e+00,\n",
      "        -1.43427501e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.45392019e-01, -1.45395705e-01],\n",
      "       [-2.86909700e+02, -1.39846145e+01, -3.83027322e+02,\n",
      "        -8.05883252e+00,  8.49694038e-02,  3.04734176e+00,\n",
      "        -1.68141414e+02, -5.11609508e+00,  0.00000000e+00,\n",
      "         2.44590273e+02,  1.39623275e+02,  0.00000000e+00,\n",
      "        -8.12062862e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         8.23899362e-02, -8.23920245e-02],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 1.67945991e+01,  8.10727913e-01,  2.24323879e+01,\n",
      "         4.57868435e-01, -5.08941727e-03, -1.82045803e-01,\n",
      "         9.84241314e+00,  2.99505881e-01,  0.00000000e+00,\n",
      "        -1.43427501e+01, -8.12062862e+00,  0.00000000e+00,\n",
      "         4.76041838e-01,  0.00000000e+00,  0.00000000e+00,\n",
      "        -4.96874647e-03,  4.96868391e-03],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "         0.00000000e+00,  0.00000000e+00],\n",
      "       [-1.69810738e-01, -8.18898138e-03, -2.26694162e-01,\n",
      "        -4.59046694e-03,  5.57168819e-05,  1.99978334e-03,\n",
      "        -9.95483214e-02, -3.02986855e-03,  0.00000000e+00,\n",
      "         1.45392019e-01,  8.23899362e-02,  0.00000000e+00,\n",
      "        -4.96874647e-03,  0.00000000e+00,  0.00000000e+00,\n",
      "         1.00004847e+00, -4.84712623e-05],\n",
      "       [ 1.69815099e-01,  8.18919766e-03,  2.26699986e-01,\n",
      "         4.59059737e-03, -5.57178796e-05, -1.99981894e-03,\n",
      "         9.95508754e-02,  3.02994621e-03,  0.00000000e+00,\n",
      "        -1.45395705e-01, -8.23920245e-02,  0.00000000e+00,\n",
      "         4.96868391e-03,  0.00000000e+00,  0.00000000e+00,\n",
      "        -4.84712623e-05,  1.00004847e+00]])\n",
      "      jac: array([-2.8880000e+04, -5.7928000e+05,  9.5241600e+05, -9.8971200e+05,\n",
      "       -3.7120000e+03, -8.9872000e+04, -4.8832000e+04, -1.2800000e+02,\n",
      "        0.0000000e+00, -1.4387680e+06, -1.2004800e+05,  0.0000000e+00,\n",
      "       -8.6336576e+07,  0.0000000e+00,  0.0000000e+00, -1.2912000e+04,\n",
      "        1.2896000e+04])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 840\n",
      "      nit: 2\n",
      "     njev: 46\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([-8.98674661e+02, -4.43571003e+01, -1.20045366e+03, -2.68898014e+01,\n",
      "        3.21139922e-01,  7.31535867e+00, -5.26222907e+02, -1.56554335e+01,\n",
      "        4.56606473e-01,  7.58773615e+02,  4.30025053e+02,  2.41412791e-01,\n",
      "        1.09852442e+01,  1.00000000e+00,  1.00000000e+00,  2.67166709e-01,\n",
      "       -2.67166287e-01])\n"
     ]
    }
   ],
   "source": [
    "#just a test block\n",
    "\n",
    "# x = np.linspace(1.01, 1.99, 40)\n",
    "# print(x)\n",
    "# a = 4\n",
    "# b = 4\n",
    "# fx = x + np.exp(-a*(1 - x)) + np.exp(-b*(x - 2))\n",
    "# # fx = x + 1/(x-1) + 1/(2 - x)\n",
    "\n",
    "# plt.plot(x, fx)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
